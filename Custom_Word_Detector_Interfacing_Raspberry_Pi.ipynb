{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom-Word-Detector-Interfacing-Raspberry-Pi.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DasAUoAGzSK-",
        "i9e6sypZHAG0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZMam-gc0zlD"
      },
      "source": [
        "# MFCC Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw5CIETJAIZ9"
      },
      "source": [
        "!pip install python_speech_features\r\n",
        "from os import listdir\r\n",
        "from os.path import isdir, join\r\n",
        "import librosa\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import python_speech_features\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l_aVkuXxi8Y"
      },
      "source": [
        "**Get Data From G Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2DBzgJbxiB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb3e053-b595-4c7d-bf15-ec363f13b11d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\r\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiPwmn9Vx5_2"
      },
      "source": [
        "# copy the .zip file into the root directory of cloud VM\r\n",
        "!cp /content/gdrive/MyDrive/Speech_Recognition/Data/test-1-31.zip ../\r\n",
        "# unzip the zip file and its contents should now be in /darknet/data/obj\r\n",
        "!unzip ../test-1-31.zip -d data/;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn_cbrfrBQmi"
      },
      "source": [
        "# Dataset path and view possible targets\r\n",
        "dataset_path = '/content/data'\r\n",
        "for name in listdir(dataset_path):\r\n",
        "    if isdir(join(dataset_path, name)):\r\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrinttTBBR2d"
      },
      "source": [
        "# Create an all targets list\r\n",
        "all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\r\n",
        "print(all_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR-pGaS4BZ28"
      },
      "source": [
        "# See how many files are in each\r\n",
        "num_samples = 0\r\n",
        "for target in all_targets:\r\n",
        "    print(len(listdir(join(dataset_path, target))))\r\n",
        "    num_samples += len(listdir(join(dataset_path, target)))\r\n",
        "print('Total samples:', num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMWLIckoBdYG"
      },
      "source": [
        "# Settings\r\n",
        "target_list = all_targets\r\n",
        "feature_sets_file = 'all_targets_mfcc_sets.npz'\r\n",
        "perc_keep_samples = 1.0 # 1.0 is keep all samples\r\n",
        "val_ratio = 0.1\r\n",
        "test_ratio = 0.1\r\n",
        "sample_rate = 8000\r\n",
        "num_mfcc = 16\r\n",
        "len_mfcc = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg6SBOaVBfMo"
      },
      "source": [
        "\r\n",
        "# Create list of filenames along with ground truth vector (y)\r\n",
        "filenames = []\r\n",
        "y = []\r\n",
        "for index, target in enumerate(target_list):\r\n",
        "    print(join(dataset_path, target))\r\n",
        "    filenames.append(listdir(join(dataset_path, target)))\r\n",
        "    y.append(np.ones(len(filenames[index])) * index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnawcZmGBhta"
      },
      "source": [
        "# Check ground truth Y vector\r\n",
        "print(y)\r\n",
        "for item in y:\r\n",
        "    print(len(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw4gIEszSw0G"
      },
      "source": [
        "y\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23IUEYMhBlJZ"
      },
      "source": [
        "\r\n",
        "# Flatten filename and y vectors\r\n",
        "filenames = [item for sublist in filenames for item in sublist]\r\n",
        "y = [item for sublist in y for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfVOaAeNRvme"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnwfTO48BnBu"
      },
      "source": [
        "# Associate filenames with true output and shuffle\r\n",
        "filenames_y = list(zip(filenames, y))\r\n",
        "random.shuffle(filenames_y)\r\n",
        "filenames, y = zip(*filenames_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-v_5WLDc8Uf"
      },
      "source": [
        "print(filenames)\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeehxvdFCNbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf09233-f077-4bfd-8420-7e81aa9106b6"
      },
      "source": [
        "# Only keep the specified number of samples (shorter extraction/training)\r\n",
        "print(len(filenames))\r\n",
        "filenames = filenames[:int(len(filenames) * perc_keep_samples)]\r\n",
        "print(len(filenames))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5729\n",
            "5729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg4HXT5eDwdd"
      },
      "source": [
        "# Calculate validation and test set sizes\r\n",
        "val_set_size = int(len(filenames) * val_ratio)\r\n",
        "test_set_size = int(len(filenames) * test_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlpJRiO7D3E0"
      },
      "source": [
        "\r\n",
        "# Break dataset apart into train, validation, and test sets\r\n",
        "filenames_val = filenames[:val_set_size]\r\n",
        "filenames_test = filenames[val_set_size:(val_set_size + test_set_size)]\r\n",
        "filenames_train = filenames[(val_set_size + test_set_size):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKVHAUavD5JD"
      },
      "source": [
        "# Break y apart into train, validation, and test sets\r\n",
        "y_orig_val = y[:val_set_size]\r\n",
        "y_orig_test = y[val_set_size:(val_set_size + test_set_size)]\r\n",
        "y_orig_train = y[(val_set_size + test_set_size):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32bppmbD7Kc"
      },
      "source": [
        "# Function: Create MFCC from given path\r\n",
        "def calc_mfcc(path):\r\n",
        "    \r\n",
        "    # Load wavefile\r\n",
        "    signal, fs = librosa.load(path, sr=sample_rate)\r\n",
        "    \r\n",
        "    # Create MFCCs from sound clip\r\n",
        "    mfccs = python_speech_features.base.mfcc(signal, \r\n",
        "                                            samplerate=fs,\r\n",
        "                                            winlen=0.256,\r\n",
        "                                            winstep=0.050,\r\n",
        "                                            numcep=num_mfcc,\r\n",
        "                                            nfilt=26,\r\n",
        "                                            nfft=2048,\r\n",
        "                                            preemph=0.0,\r\n",
        "                                            ceplifter=0,\r\n",
        "                                            appendEnergy=False,\r\n",
        "                                            winfunc=np.hanning)\r\n",
        "    return mfccs.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEoUpnORzXC-"
      },
      "source": [
        "### Checking Corrupt Data And Fixing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_7Xgiy2EAWd"
      },
      "source": [
        "# TEST: Construct test set by computing MFCC of each WAV file\r\n",
        "prob_cnt = 0\r\n",
        "x_test = []\r\n",
        "y_test = []\r\n",
        "for index, filename in enumerate(filenames_train):\r\n",
        "    \r\n",
        "    # Stop after 500\r\n",
        "    if index >= 500:\r\n",
        "        break\r\n",
        "    \r\n",
        "    # Create path from given filename and target item\r\n",
        "    path = join(dataset_path, target_list[int(y_orig_train[index])], \r\n",
        "                filename)\r\n",
        "    \r\n",
        "    # Create MFCCs\r\n",
        "    mfccs = calc_mfcc(path)\r\n",
        "    \r\n",
        "    if mfccs.shape[1] == len_mfcc:\r\n",
        "        x_test.append(mfccs)\r\n",
        "        y_test.append(y_orig_train[index])\r\n",
        "    else:\r\n",
        "        print('Dropped:', index, mfccs.shape)\r\n",
        "        prob_cnt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD3RYP8EEBdU"
      },
      "source": [
        "print('% of problematic samples:', prob_cnt / 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyAI-OVGXZep"
      },
      "source": [
        "%%capture\r\n",
        "! apt-get update && apt-get -y --no-install-recommends install \\\r\n",
        "    sudo \\\r\n",
        "    gstreamer-1.0 \\\r\n",
        "    gstreamer1.0-gtk3\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR_7rNsl97gX"
      },
      "source": [
        "! apt-get update && apt-get -y --no-install-recommends install \\\r\n",
        "    sudo \\\r\n",
        "    vim \\\r\n",
        "    wget \\\r\n",
        "    build-essential \\\r\n",
        "    pkg-config \\\r\n",
        "    python3.6 \\\r\n",
        "    python3-pip \\\r\n",
        "    python3.6-dev \\\r\n",
        "    python3.6-venv \\\r\n",
        "    python-dev \\\r\n",
        "    python3-dev \\\r\n",
        "    git \\\r\n",
        "    cmake \\\r\n",
        "    autoconf \\\r\n",
        "    automake \\\r\n",
        "    libtool \\\r\n",
        "    gstreamer-1.0 \\\r\n",
        "    gstreamer1.0-dev \\\r\n",
        "    libgstreamer1.0-0 \\\r\n",
        "    gstreamer1.0-plugins-base \\\r\n",
        "    gstreamer1.0-plugins-good \\\r\n",
        "    gstreamer1.0-plugins-bad \\\r\n",
        "    gstreamer1.0-plugins-ugly \\\r\n",
        "    gstreamer1.0-libav \\\r\n",
        "    gstreamer1.0-doc \\\r\n",
        "    gstreamer1.0-tools \\\r\n",
        "    gstreamer1.0-x \\\r\n",
        "    gstreamer1.0-alsa \\\r\n",
        "    gstreamer1.0-gl \\\r\n",
        "    gstreamer1.0-gtk3 \\\r\n",
        "    gstreamer1.0-qt5 \\\r\n",
        "    gstreamer1.0-pulseaudio \\\r\n",
        "    python-gst-1.0 \\\r\n",
        "    libgirepository1.0-dev \\\r\n",
        "    libgstreamer-plugins-base1.0-dev \\\r\n",
        "    libcairo2-dev \\\r\n",
        "    gir1.2-gstreamer-1.0 \\\r\n",
        "    python3-gi \\\r\n",
        "    python-gi-dev\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqxz6i2lEFa6"
      },
      "source": [
        "# TEST: Test shorter MFCC\r\n",
        "!pip install playsound\r\n",
        "from playsound import playsound\r\n",
        "#sudo apt-get install gstreamer-1.0\r\n",
        "\r\n",
        "idx = 290\r\n",
        "\r\n",
        "# Create path from given filename and target item\r\n",
        "path = join(dataset_path, target_list[int(y_orig_train[idx])], \r\n",
        "            filenames_train[idx])\r\n",
        "print(path)\r\n",
        "# Create MFCCs\r\n",
        "mfccs = calc_mfcc(path)\r\n",
        "print(\"MFCCs:\", mfccs)\r\n",
        "\r\n",
        "# Plot MFCC\r\n",
        "fig = plt.figure()\r\n",
        "plt.imshow(mfccs, cmap='inferno', origin='lower')\r\n",
        "\r\n",
        "# TEST: Play problem sounds\r\n",
        "print(target_list[int(y_orig_train[idx])])\r\n",
        "#playsound(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_7_Da7CbwbA"
      },
      "source": [
        "from PyQt5.QtWidgets import QMainWindow, QLabel, QSizePolicy, QApplication \r\n",
        "from PyQt5.QtGui import QPixmap, QImage                                \r\n",
        "from PyQt5.QtCore import Qt                 \r\n",
        "qImage = array2qimage(mfccs, normalize = False) # create QImage from ndarray\r\n",
        "success = qImage.save('aaa') # use Qt's image IO functions for saving PNG/JPG/.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5MCqaEHePcV"
      },
      "source": [
        "from PIL import Image\r\n",
        "im = Image.fromarray(mfccs)\r\n",
        "im = im.convert('RGB')\r\n",
        "im.save(\"your_file.jpeg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7UnasBs-fgC"
      },
      "source": [
        "\r\n",
        "import os\r\n",
        "filenames_train[290]\r\n",
        "os.path.splitext(filenames_train[290])[0]\r\n",
        "%cd '/content/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbb3S_mgWOeJ"
      },
      "source": [
        "# Importing Image module from PIL package  \r\n",
        "from PIL import Image  \r\n",
        "import PIL  \r\n",
        "  \r\n",
        "# creating a image object (main image)  \r\n",
        "#im1 = Image.open(r\"C:\\Users\\System-Pc\\Desktop\\flower1.jpg\")  \r\n",
        "im1 = Image.open(mfccs)  \r\n",
        "  \r\n",
        "# save a image using extension \r\n",
        "%cd '/content'\r\n",
        "im1 = mfccs.save(os.path.splitext(filenames_train[290])[0]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DasAUoAGzSK-"
      },
      "source": [
        "### Creating Mfcc & Output file\r\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WXzSJxZEI7q"
      },
      "source": [
        "# Function: Create MFCCs, keeping only ones of desired length\r\n",
        "def extract_features(in_files, in_y):\r\n",
        "    prob_cnt = 0\r\n",
        "    out_x = []\r\n",
        "    out_y = []\r\n",
        "        \r\n",
        "    for index, filename in enumerate(in_files):\r\n",
        "    \r\n",
        "        # Create path from given filename and target item\r\n",
        "        path = join(dataset_path, target_list[int(in_y[index])], \r\n",
        "                    filename)\r\n",
        "        \r\n",
        "        # Check to make sure we're reading a .wav file\r\n",
        "        if not path.endswith('.wav'):\r\n",
        "            continue\r\n",
        "\r\n",
        "        # Create MFCCs\r\n",
        "        mfccs = calc_mfcc(path)\r\n",
        "\r\n",
        "        # Only keep MFCCs with given length\r\n",
        "        if mfccs.shape[1] == len_mfcc:\r\n",
        "            out_x.append(mfccs)\r\n",
        "            out_y.append(in_y[index])\r\n",
        "        else:\r\n",
        "            print('Dropped:', index, mfccs.shape)\r\n",
        "            prob_cnt += 1\r\n",
        "\r\n",
        "        \r\n",
        "            \r\n",
        "    return out_x, out_y, prob_cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0B8ZBoHhewu"
      },
      "source": [
        "print(x_val[2])\r\n",
        "imshow(x_val[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiY7xUT-ELcP"
      },
      "source": [
        "# Create train, validation, and test sets\r\n",
        "x_train, y_train, prob = extract_features(filenames_train, \r\n",
        "                                          y_orig_train)\r\n",
        "print('Removed percentage:', prob / len(y_orig_train))\r\n",
        "x_val, y_val, prob = extract_features(filenames_val, y_orig_val)\r\n",
        "print('Removed percentage:', prob / len(y_orig_val))\r\n",
        "x_test, y_test, prob = extract_features(filenames_test, y_orig_test)\r\n",
        "print('Removed percentage:', prob / len(y_orig_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jKCozYEPeA"
      },
      "source": [
        "# Save features and truth vector (y) sets to disk\r\n",
        "np.savez(feature_sets_file, \r\n",
        "         x_train=x_train, \r\n",
        "         y_train=y_train, \r\n",
        "         x_val=x_val, \r\n",
        "         y_val=y_val, \r\n",
        "         x_test=x_test, \r\n",
        "         y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slUhhXx3ESWq"
      },
      "source": [
        "# TEST: Load features\r\n",
        "feature_sets = np.load(feature_sets_file)\r\n",
        "feature_sets.files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOlhHbliET1M"
      },
      "source": [
        "len(feature_sets['x_train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REsGb9e8EVcc"
      },
      "source": [
        "print(feature_sets['y_val'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_sBiKag059v"
      },
      "source": [
        "# Model Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhd6Je9zXJb9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dbfVrIResrv"
      },
      "source": [
        "#############Save As Image################\r\n",
        "from PIL import Image\r\n",
        "im = Image.fromarray(A)\r\n",
        "im.save(\"your_file.jpeg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJVMEPDaD7bl"
      },
      "source": [
        "# multi-class classification with Keras\r\n",
        "import pandas\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from keras.utils import np_utils\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "# load dataset\r\n",
        "dataframe = pandas.read_csv(\"iris.data\", header=None)\r\n",
        "dataset = dataframe.values\r\n",
        "X = dataset[:,0:4].astype(float)\r\n",
        "Y = dataset[:,4]\r\n",
        "# encode class values as integers\r\n",
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(Y)\r\n",
        "encoded_Y = encoder.transform(Y)\r\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\r\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\r\n",
        "\r\n",
        "# define baseline model\r\n",
        "def baseline_model():\r\n",
        "\t# create model\r\n",
        "\tmodel = Sequential()\r\n",
        "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\r\n",
        "\tmodel.add(Dense(3, activation='softmax'))\r\n",
        "\t# Compile model\r\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\treturn model\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQYxN2Tn0kMn"
      },
      "source": [
        "import pandas\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from keras.utils import np_utils\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from os import listdir\r\n",
        "from os.path import isdir, join\r\n",
        "from tensorflow.keras import layers, models\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bllOVvgF1spS"
      },
      "source": [
        "print(dataset_path)\r\n",
        "print(all_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HgE9BGq1C-d"
      },
      "source": [
        "# Settings\r\n",
        "feature_sets_path = '/content'\r\n",
        "feature_sets_filename = 'all_targets_mfcc_sets.npz'\r\n",
        "model_filename = 'wake_word_stop_model.h5'\r\n",
        "#wake_word = 'stop'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEeSvcJ41H3n"
      },
      "source": [
        "# Load feature sets\r\n",
        "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\r\n",
        "print(feature_sets.files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArQio_01QNJ"
      },
      "source": [
        "# Assign feature sets\r\n",
        "x_train = feature_sets['x_train']\r\n",
        "y_train = feature_sets['y_train']\r\n",
        "x_val = feature_sets['x_val']\r\n",
        "y_val = feature_sets['y_val']\r\n",
        "x_test = feature_sets['x_test']\r\n",
        "y_test = feature_sets['y_test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mMDUg5l1UI_"
      },
      "source": [
        "# Look at tensor dimensions\r\n",
        "print(x_train.shape)\r\n",
        "print(x_val.shape)\r\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8UdYNGh1Wb2"
      },
      "source": [
        "\r\n",
        "# Peek at labels\r\n",
        "print(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npk1Pie-FQM1"
      },
      "source": [
        "\r\n",
        "# #############Encode Y##########################################\r\n",
        "# encoder = LabelEncoder()\r\n",
        "# encoder.fit(y_train)\r\n",
        "# encoded_y_train = encoder.transform(y_train)\r\n",
        "# encoder.fit(y_val)\r\n",
        "# encoded_y_val = encoder.transform(y_val)\r\n",
        "# encoder.fit(y_test)\r\n",
        "# encoded_y_test = encoder.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnaymViWOYrD"
      },
      "source": [
        "dummy_y_train = np_utils.to_categorical(encoded_y_train)\r\n",
        "dummy_y_test = np_utils.to_categorical(encoded_y_test)\r\n",
        "dummy_y_val = np_utils.to_categorical(encoded_y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIc2q4A1yKid"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHYFpj41X_-"
      },
      "source": [
        "# Convert ground truth arrays to one wake word (1) and 'other' (0)\r\n",
        "#wake_word_index = all_targets.index(wake_word)\r\n",
        "#y_train = np.equal(y_train, wake_word_index).astype('float64')\r\n",
        "#y_val = np.equal(y_val, wake_word_index).astype('float64')\r\n",
        "#y_test = np.equal(y_test, wake_word_index).astype('float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HoK8F151aUH"
      },
      "source": [
        "# Peek at labels after conversion\r\n",
        "print(encoded_y_val)\r\n",
        "print(dummy_y_val)\r\n",
        "#print(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Dlr_Rp1btU"
      },
      "source": [
        "# What percentage of 'stop' appear in validation labels\r\n",
        "print(sum(y_val) / len(y_val))\r\n",
        "print(1 - sum(y_val) / len(y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0b173F1dZS"
      },
      "source": [
        "# View the dimensions of our input data\r\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_oZwrqR1fzp"
      },
      "source": [
        "# CNN for TF expects (batch, height, width, channels)\r\n",
        "# So we reshape the input tensors with a \"color\" channel of 1\r\n",
        "x_train = x_train.reshape(x_train.shape[0], \r\n",
        "                          x_train.shape[1], \r\n",
        "                          x_train.shape[2], \r\n",
        "                          1)\r\n",
        "x_val = x_val.reshape(x_val.shape[0], \r\n",
        "                      x_val.shape[1], \r\n",
        "                      x_val.shape[2], \r\n",
        "                      1)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], \r\n",
        "                        x_test.shape[1], \r\n",
        "                        x_test.shape[2], \r\n",
        "                        1)\r\n",
        "print(x_train.shape)\r\n",
        "print(x_val.shape)\r\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdgHTfFm1grt"
      },
      "source": [
        "\r\n",
        "# Input shape for CNN is size of MFCC of 1 sample\r\n",
        "sample_shape = x_test.shape[1:]\r\n",
        "print(sample_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLKZ7pIJ1loU"
      },
      "source": [
        "# Build model\r\n",
        "# Based on: https://www.geeksforgeeks.org/python-image-classification-using-keras/\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Conv2D(32, \r\n",
        "                        (2, 2), \r\n",
        "                        activation='relu',\r\n",
        "                        input_shape=sample_shape))\r\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(layers.Conv2D(32, (2, 2), activation='relu'))\r\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "model.add(layers.Conv2D(64, (2, 2), activation='relu'))\r\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "# Classifier\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(64, activation='relu'))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeqlfGD71oaK"
      },
      "source": [
        "\r\n",
        "# Display model\r\n",
        "model.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Fdj48Z1pHL"
      },
      "source": [
        "# Add training parameters to model\r\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \r\n",
        "              optimizer='adam', \r\n",
        "              metrics=['accuracy'])\r\n",
        "#model.compile(optimizer='adam',                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),               metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXUZX9daMSI_"
      },
      "source": [
        "num_classes = 3 #number of classes, here is 10 (0,1,...,9)\r\n",
        "train_y = keras.utils.to_categorical(encoded_y_train, num_classes)\r\n",
        "test_y = keras.utils.to_categorical(encoded_y_test, num_classes)\r\n",
        "val_y = keras.utils.to_categorical(encoded_y_val, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrxvuVk21uLo"
      },
      "source": [
        "# Train\r\n",
        "history = model.fit(x_train, \r\n",
        "                    dummy_y_train, \r\n",
        "                    epochs=30, \r\n",
        "                    batch_size=300, \r\n",
        "                    validation_data=(x_val, dummy_y_val)\r\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jz-tcoY1zAG"
      },
      "source": [
        "# Plot results\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(1, len(acc) + 1)\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ0aiI1T11h5"
      },
      "source": [
        "# Save the model as a file\r\n",
        "models.save_model(model, model_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOUCkRZf13gu"
      },
      "source": [
        "\r\n",
        "# See which are 'stop'\r\n",
        "for idx, y in enumerate(encoded_y_test):\r\n",
        "    if y == 1:\r\n",
        "        print(idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ9Hczmb14hY"
      },
      "source": [
        "# TEST: Load model and run it against test set\r\n",
        "model = models.load_model(model_filename)\r\n",
        "for i in range(100, 110):\r\n",
        "    print('Answer:', encoded_y_test[i], ' Prediction:', model.predict(np.expand_dims(x_test[i], 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWsK4NFr17l9"
      },
      "source": [
        "# Evaluate model with test set\r\n",
        "model.evaluate(x=x_test, y=encoded_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9e6sypZHAG0"
      },
      "source": [
        "# Cross validation for Unsplitted DAta set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY5E2Kn6G-8j"
      },
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\r\n",
        "kfold = KFold(n_splits=10, shuffle=True)\r\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\r\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}